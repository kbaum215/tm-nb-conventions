{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kevinbaum/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE FROM KB: First I gather up what the data tables are called in the data. I find that the database contains just one table that is called \"conventions.\" I then produce what the schema is called. To get the text, we can query \"text\" and \"party\" for this part of the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database:\n",
      "conventions\n",
      "\n",
      "Schema of 'conventions' table:\n",
      "(0, 'party', 'TEXT', 0, None, 0)\n",
      "(1, 'night', 'INTEGER', 0, None, 0)\n",
      "(2, 'speaker', 'TEXT', 0, None, 0)\n",
      "(3, 'speaker_count', 'INTEGER', 0, None, 0)\n",
      "(4, 'time', 'TEXT', 0, None, 0)\n",
      "(5, 'text', 'TEXT', 0, None, 0)\n",
      "(6, 'text_len', 'TEXT', 0, None, 0)\n",
      "(7, 'file', 'TEXT', 0, None, 0)\n"
     ]
    }
   ],
   "source": [
    "# Query to get the list of all tables\n",
    "tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "convention_cur.execute(tables_query)\n",
    "\n",
    "# Fetch the tables\n",
    "tables = convention_cur.fetchall()\n",
    "\n",
    "print(\"Tables in the database:\")\n",
    "for table in tables:\n",
    "    print(table[0])\n",
    "\n",
    "# Get the schema of the conventions table\n",
    "for table in tables:\n",
    "    print(f\"\\nSchema of '{table[0]}' table:\")\n",
    "    pragma_query = f\"PRAGMA table_info({table[0]});\"\n",
    "    convention_cur.execute(pragma_query)\n",
    "    columns = convention_cur.fetchall()\n",
    "    for column in columns:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE FROM KB: Below I write a function that first cleans the text, tokenizes it, and then finally removes stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "def clean_tokenize(text):\n",
    "    # Clean the text\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove non-alphabetic characters and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "\n",
    "    return ' '.join(tokens) \n",
    "\n",
    "# Getting text then party from the conventions table\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT party, text FROM conventions\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    cleaned_text = clean_tokenize(row[1])\n",
    "    # Append the rows into the convention_data list\n",
    "    convention_data.append([cleaned_text, row[0]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['congratulations youre citizens united states america behalf department homeland security honor call fellow americans mr president want commend dedication rule law restoring integrity immigration system thank hosting patriotic celebration white house today',\n",
       "  'Republican'],\n",
       " ['im pleased announce vice president joe biden officially nominated democratic party candidate president united states',\n",
       "  'Democratic'],\n",
       " ['every generation us fight believe turn jack g proud saw demonstrations going across country',\n",
       "  'Democratic'],\n",
       " ['joe biden selected kamala harris running mate', 'Democratic'],\n",
       " ['american history tells us thats darkest moments weve made greatest progress found light dark moment believe poised make great progress find light',\n",
       "  'Democratic'],\n",
       " ['im reelected best yet come thank much took office middle east total chaos isis rampaging iran rise war afghanistan end sight',\n",
       "  'Republican'],\n",
       " ['im rebecca friedrichs veteran california public school educator im give voice americas great teachers voices silenced decades unions claim represent us dedicated teachers served within unions spoke defense children parents scientific fact american values trouble brutalized booed platform barred committees shouted even spit upon union leaders unions treat devoted teachers whats even worse agenda control deceives americans children theyve intentionally rewritten american history perpetuate division pervert memories american founders disparage judeochristian virtues theyre lenient discipline policies morphed schools war zones back defunding police abolishing ice unions collect billions annually unsuspecting teachers push radical agenda classrooms',\n",
       "  'Republican'],\n",
       " ['gave energy students shes great teacher', 'Democratic'],\n",
       " ['team usa indeed take home gold', 'Republican'],\n",
       " ['skip content company careers press freelancers blog services transcription captions foreign subtitles translation freelancers contact login return transcript library home transcript categories transcripts election transcripts classic speech transcripts congressional testimony hearing transcripts debate transcripts donald trump transcripts entertainment transcripts financial transcripts interview transcripts political transcripts press conference transcripts speech transcripts sports transcripts technology transcripts aug democratic national convention dnc night transcript speeches barack obama kamala harris hillary clinton nancy pelosi rev blog transcripts election transcripts democratic national convention dnc night transcript speeches barack obama kamala harris hillary clinton nancy pelosi night democratic national convention dnc august speakers include sen vicepresidential nominee kamala harris former sec state democratic nominee hillary clinton house speaker nancy pelosi sen elizabeth warren former president barack obama read full transcript event transcribe content try rev free save time transcribing captioning subtitling',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2327 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    # Create a dictionary for the features\n",
    "    ret_dict = dict()\n",
    "\n",
    "    # Check each word in the text\n",
    "    for word in words:\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,\"citizens\":True})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.494\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                  defund = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "KB: One of the most interesting ones is China. I actually think the China issue has become somewhat more bipartisan since the last election cycle. It always seemed to me that Republicans would imply or accuse Democrats of being sympathetic towards communist China and that Democrats would likewise imply or accuse Republicans of being sympathetic towards nationalist, church/state unified Russia. Trump definitely made it a point of his presidency to antagonize China more than previous presidents by pushing the trade war. Therefore, it is not a surprise that it was a major talking point of Republicans in 2020. However, I bet if we re-did this analysis in 2024, the proportion difference would be much narrower. That would be an interesting topic to test. \n",
    "\n",
    "Something else that stands out is how many more Republican buzzwords there are than Democrat buzzwords. Of the 25 words, only two are Democrat words. This tells me that perhaps the dataset is very biased towards containing Republican content or Republican buzzwords. It could also mean that Republicans simply focus more intensely on certain subjects than Democrats do. However, I doubt this is the case. It would be worthwhile to explore more about the dataset to understand why the Republican words stick out like this.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "for candidate, party, tweet_text in results:\n",
    "    # Decode the tweet_text from bytes to string\n",
    "    if isinstance(tweet_text, bytes):\n",
    "        tweet_text = tweet_text.decode('utf-8')\n",
    "\n",
    "    # Preprocess the tweet\n",
    "    cleaned_text = clean_tokenize(tweet_text)\n",
    "\n",
    "    # Create a feature set for the tweet\n",
    "    feature_set = conv_features(cleaned_text, feature_words)\n",
    "\n",
    "    # Append the tuple (feature set, party) to tweet_data\n",
    "    tweet_data.append((feature_set, party))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: {'earlier': True, 'today': True, 'spoke': True, 'house': True, 'floor': True, 'protecting': True, 'health': True, 'care': True, 'women': True, 'work': True, 'coast': True}\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'go': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: {'trump': True, 'thinks': True, 'easy': True, 'students': True, 'burden': True, 'debt': True, 'pay': True, 'student': True}\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'grateful': True, 'first': True, 'responders': True, 'rescue': True, 'police': True, 'working': True, 'tirelessly': True, 'keep': True, 'people': True, 'safe': True, 'provide': True, 'help': True, 'putting': True, 'lives': True, 'line': True}\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'lets': True, 'make': True, 'even': True, 'greater': True}\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'im': True, 'scared': True}\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'new': True, 'city': True, 'glad': True, 'continue': True, 'serve': True}\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'really': True, 'close': True, 'raised': True, 'toward': True, 'right': True, 'thats': True, 'room': True, 'help': True, 'us': True, 'get': True}\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'today': True, 'plan': True, 'expand': True, 'opened': True, 'public': True, 'days': True, 'march': True, 'share': True, 'program': True, 'trump': True, 'administration': True, 'made': True, 'email': True, 'mail': True}\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'celebrated': True, 'years': True, 'commitment': True, 'community': True, 'leaders': True, 'last': True, 'nights': True}\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    \n",
    "    # Use the classifier to estimate the party\n",
    "    estimated_party = classifier.classify(tweet)\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(tweet)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3748, 'Democratic': 530}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4855, 'Democratic': 869})})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_Write a little about what you see in the results_ \n",
    "\n",
    "KB: Like I talked about above, the dataset seems to have a heavy Republican bias, where most of the tweets are Republican. The model does a good job of classifying the Republican the Republican ones as Republican but a poor job of identifying the Democrat ones as Democrat. One way of improving the model would be to use a more balanced training set that skews towards containing a lower proportion of Republican tweets to Democrat tweets. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
